{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PySpark for NLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b3977627be37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHashingTF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIDF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a fake example\n",
    "  - Need to import pyspark.sql module for dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# initialise sparkContext\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"fakeExample\") \\\n",
    "    .config(\"spark.executor.memory\", \"5gb\") \\\n",
    "    .config(\"spark.cores.max\", \"6\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|  _1|  _2|\n",
      "+----+----+\n",
      "| aaa|none|\n",
      "|gggg| 0.2|\n",
      "| ggs|  .3|\n",
      "| bbb|none|\n",
      "|pppp| 0.2|\n",
      "| pps|  .3|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "dt = sc.parallelize(['aaa\\tgggg:0.2|ggs:.3','bbb\\tpppp:0.2|pps:.3' ])\n",
    "dt2 = dt.map(lambda x: x.replace(\"\\t\", \":none|\")).flatMap(lambda x: x.split(\"|\")).map(lambda x: x.split(\":\"))\n",
    "dt2.toDF().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            sentence|\n",
      "+-----+--------------------+\n",
      "|  0.0|Hi I heard about ...|\n",
      "|  0.0|I wish Java could...|\n",
      "|  1.0|Logistic regressi...|\n",
      "+-----+--------------------+\n",
      "\n",
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- sentence: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentenceData = spark.createDataFrame([\n",
    "    (0.0, \"Hi I heard about Spark\"),\n",
    "    (0.0, \"I wish Java could use case classes\"),\n",
    "    (1.0, \"Logistic regression models are neat\")\n",
    "], [\"label\", \"sentence\"])\n",
    "\n",
    "sentenceData.show()\n",
    "sentenceData.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokernization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, sentence: string, terms: array<string>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|            sentence|               terms|\n",
      "+-----+--------------------+--------------------+\n",
      "|  0.0|Hi I heard about ...|[hi, i, heard, ab...|\n",
      "|  0.0|I wish Java could...|[i, wish, java, c...|\n",
      "|  1.0|Logistic regressi...|[logistic, regres...|\n",
      "+-----+--------------------+--------------------+\n",
      "\n",
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- sentence: string (nullable = true)\n",
      " |-- terms: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize an instance\n",
    "tokenizer = Tokenizer(inputCol= \"sentence\", outputCol=\"terms\")\n",
    "termData = tokenizer.transform(sentenceData)\n",
    "display(termData)\n",
    "termData.show()\n",
    "termData.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, sentence: string, terms: array<string>, rawfeature: vector]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+\n",
      "|label|            sentence|               terms|          rawfeature|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "|  0.0|Hi I heard about ...|[hi, i, heard, ab...|(10,[0,5,7,9],[1....|\n",
      "|  0.0|I wish Java could...|[i, wish, java, c...|(10,[2,3,5,7,9],[...|\n",
      "|  1.0|Logistic regressi...|[logistic, regres...|(10,[3,4,5,6,8],[...|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "\n",
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- sentence: string (nullable = true)\n",
      " |-- terms: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "+--------------------+\n",
      "|          rawfeature|\n",
      "+--------------------+\n",
      "|(10,[0,5,7,9],[1....|\n",
      "|(10,[2,3,5,7,9],[...|\n",
      "|(10,[3,4,5,6,8],[...|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(label=0.0, sentence='Hi I heard about Spark', terms=['hi', 'i', 'heard', 'about', 'spark'], rawfeature=SparseVector(10, {0: 1.0, 5: 1.0, 7: 2.0, 9: 1.0})),\n",
       " Row(label=0.0, sentence='I wish Java could use case classes', terms=['i', 'wish', 'java', 'could', 'use', 'case', 'classes'], rawfeature=SparseVector(10, {2: 1.0, 3: 1.0, 5: 1.0, 7: 1.0, 9: 3.0})),\n",
       " Row(label=1.0, sentence='Logistic regression models are neat', terms=['logistic', 'regression', 'models', 'are', 'neat'], rawfeature=SparseVector(10, {3: 1.0, 4: 1.0, 5: 1.0, 6: 1.0, 8: 1.0}))]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashingTF = HashingTF(inputCol=\"terms\",  outputCol=\"rawfeature\", numFeatures=10)\n",
    "featureizeData = hashingTF.transform(termData)\n",
    "display(featureizeData)\n",
    "featureizeData.show()\n",
    "termData.printSchema()\n",
    "featureizeData.select(\"rawfeature\").show()\n",
    "a = featureizeData.collect()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|             feature|\n",
      "+-----+--------------------+\n",
      "|  0.0|(10,[0,5,7,9],[0....|\n",
      "|  0.0|(10,[2,3,5,7,9],[...|\n",
      "|  1.0|(10,[3,4,5,6,8],[...|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idf = IDF(inputCol=\"rawfeature\", outputCol=\"feature\")\n",
    "idfModel = idf.fit(featureizeData)\n",
    "rescalData = idfModel.transform(featureizeData)\n",
    "\n",
    "rescalData.select(\"label\", \"feature\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('tf': conda)",
   "language": "python",
   "name": "python38564bittfconda1003bacc7caa452f8a24498035651426"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
