{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor: multidimensional array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 0.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.ones(3)\n",
    "b = torch.tensor([1, 2, 3])\n",
    "c = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "display(a)\n",
    "display(b)\n",
    "display(c)\n",
    "\n",
    "a[2] = 0\n",
    "display(a)\n",
    "display(c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 5, 6]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(c[1:, :])\n",
    "display(c[:-1, :])\n",
    "# adda dimension of size 1\n",
    "display(a[None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape\n",
    "- 2D: [rows, columns]\n",
    "- 3D: [channels, rows, columns]\n",
    "- 4D: [batch, channels, rows, columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 2])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4865,  0.0962],\n",
       "         [ 0.7658,  0.1216],\n",
       "         [-0.1652,  0.4061]],\n",
       "\n",
       "        [[-0.5511, -0.1978],\n",
       "         [ 0.3317,  0.9777],\n",
       "         [ 1.2755, -0.7287]],\n",
       "\n",
       "        [[-0.5899, -1.0735],\n",
       "         [-0.2383,  1.4534],\n",
       "         [-0.1964, -0.2633]],\n",
       "\n",
       "        [[ 1.8038, -0.0582],\n",
       "         [ 1.7271, -0.1990],\n",
       "         [ 0.5216, -0.8536]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_random_array = torch.randn(4, 3, 2)\n",
    "display(test_random_array.shape)\n",
    "display(test_random_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why we store data in a `tensor`\n",
    "In Python\n",
    "1. Numbers are objects --> operation boxing will make allocating millions inefficient\n",
    "2. Lists are used for collections of objects --> Inefficiency, especially for multidimensional data\n",
    "3. Interpreter code is slower than compiled code. --> optimize code by low-level language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric types\n",
    "1. `torch.float16` = `torch.half: 16-bit half-precision floating-point \n",
    "2. `torch.float32` = `torch.float: 32-bit floating-point (default)\n",
    "3. `torch.float64` = `torch.double`: 64-bit floating-point\n",
    "4. `torch.int8`: signed 8-bit integers\n",
    "5. `torch.uint8`: unsigned 8-bit integers\n",
    "6. `torch.int16` = `torch.short`: signed 16-bit integers\n",
    "7. `torch.int32` = `torch.int`: signed 32-bit integers\n",
    "8. `torch.int64` = `torch.long`: signed 64-bit integers\n",
    "9. `torch.bool`: Boolean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1903],\n",
       "        [-0.6681]], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1],\n",
       "        [3, 2]], dtype=torch.int16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "double_vector = torch.randn(2, 1, dtype=torch.double)\n",
    "short_array = torch.tensor([[2, 1], [3, 2]], dtype=torch.short)\n",
    "display(double_vector)\n",
    "display(short_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [0]], dtype=torch.int16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True, True],\n",
       "        [True, True]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(double_vector.short())\n",
    "display(short_array.to(dtype=torch.bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations\n",
    "1. creation ops -- construnct a tensor, e.g., `ones`, `from_numpy`\n",
    "2. Indexing, slicing, joining, mutating ops -- change the shape, stride, or content of a tensor, e..g, `transpose`\n",
    "3. Math ops -- manipulate the content of the tensor through computations\n",
    "    - Poinwise ops -- obtain a new tensor by applying a function to each element independently, e.g., `abs`, `cos` \n",
    "    - Reduction ops -- computing aggregate values, e.g., `mean`, `std`, `norm`\n",
    "    - Comparison ops -- evaluate numerical predicates over tensors, e.g.,  `equal`, `max`\n",
    "    - Spectral ops -- transform in and operate in the frequency domain, e.g., `stft`, `hamming_window`\n",
    "    - Other -- e.g., `cross`, `trace`\n",
    "    - BLAS and LAPACK operations -- Basic Linear Algebra Subprograms (BLAS) specification for scalar, vector-vector, matrix-vector, and matrix-matrix operations\n",
    "4. Random sampling -- generate values by drawing randomly from distributions, e.g., `randn`, `normal`\n",
    "5. Serialization -- save and load tensors, e.g., `load`, `save`\n",
    "6. Parallelism -- control the number of threads for parallel CPU execution `set_num_threads`\n",
    "\n",
    "### Example: `transpose`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mat = torch.ones(3, 2)\n",
    "mat_t = torch.transpose(mat, 0, 1)\n",
    "mat_t2 = mat.transpose(0, 1)\n",
    "display(mat)\n",
    "display(mat_t)\n",
    "display(mat_t == mat_t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "img_array = imageio.imread(\"image/sample.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1332, 1332, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type is <class 'imageio.core.util.Array'>\n"
     ]
    }
   ],
   "source": [
    "display(img_array.shape)\n",
    "print(f\"Type is {type(img_array)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[255, 255, 255, 255],\n",
       "         [255, 255, 255, 255],\n",
       "         [255, 255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255, 255],\n",
       "         [255, 255, 255, 255],\n",
       "         [255, 255, 255, 255]],\n",
       "\n",
       "        [[255, 255, 255, 255],\n",
       "         [255, 255, 255, 255],\n",
       "         [255, 255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255, 255],\n",
       "         [255, 255, 255, 255],\n",
       "         [255, 255, 255, 255]],\n",
       "\n",
       "        [[255, 255, 255, 255],\n",
       "         [255, 255, 255, 255],\n",
       "         [255, 255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255, 255],\n",
       "         [255, 255, 255, 255],\n",
       "         [255, 255, 255, 255]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[255, 255, 255, 255],\n",
       "         [255, 255, 255, 255],\n",
       "         [255, 255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255, 255],\n",
       "         [255, 255, 255, 255],\n",
       "         [255, 255, 255, 255]],\n",
       "\n",
       "        [[153, 153, 153, 255],\n",
       "         [153, 153, 153, 255],\n",
       "         [153, 153, 153, 255],\n",
       "         ...,\n",
       "         [153, 153, 153, 255],\n",
       "         [153, 153, 153, 255],\n",
       "         [153, 153, 153, 255]],\n",
       "\n",
       "        [[203, 203, 203, 255],\n",
       "         [203, 203, 203, 255],\n",
       "         [203, 203, 203, 255],\n",
       "         ...,\n",
       "         [203, 203, 203, 255],\n",
       "         [203, 203, 203, 255],\n",
       "         [203, 203, 203, 255]]], dtype=torch.uint8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = torch.from_numpy(img_array)\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the layout\n",
    "- Use tensor's `permute` from the old dimensions to new ones.\n",
    "    - the operation does not make a copy of the tensor data\n",
    "    - use the same storage of the tensor data \n",
    "    - stride information at the tensor level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[255, 255, 255,  ..., 255, 255, 255],\n",
       "         [255, 255, 255,  ..., 255, 255, 255],\n",
       "         [255, 255, 255,  ..., 255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255,  ..., 255, 255, 255],\n",
       "         [153, 153, 153,  ..., 153, 153, 153],\n",
       "         [203, 203, 203,  ..., 203, 203, 203]],\n",
       "\n",
       "        [[255, 255, 255,  ..., 255, 255, 255],\n",
       "         [255, 255, 255,  ..., 255, 255, 255],\n",
       "         [255, 255, 255,  ..., 255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255,  ..., 255, 255, 255],\n",
       "         [153, 153, 153,  ..., 153, 153, 153],\n",
       "         [203, 203, 203,  ..., 203, 203, 203]],\n",
       "\n",
       "        [[255, 255, 255,  ..., 255, 255, 255],\n",
       "         [255, 255, 255,  ..., 255, 255, 255],\n",
       "         [255, 255, 255,  ..., 255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255,  ..., 255, 255, 255],\n",
       "         [153, 153, 153,  ..., 153, 153, 153],\n",
       "         [203, 203, 203,  ..., 203, 203, 203]],\n",
       "\n",
       "        [[255, 255, 255,  ..., 255, 255, 255],\n",
       "         [255, 255, 255,  ..., 255, 255, 255],\n",
       "         [255, 255, 255,  ..., 255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255,  ..., 255, 255, 255],\n",
       "         [255, 255, 255,  ..., 255, 255, 255],\n",
       "         [255, 255, 255,  ..., 255, 255, 255]]], dtype=torch.uint8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = image.permute(2, 0, 1)\n",
    "display(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
